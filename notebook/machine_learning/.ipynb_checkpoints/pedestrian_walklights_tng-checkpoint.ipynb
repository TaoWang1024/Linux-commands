{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffeb037-5575-4fd6-a40e-51078e9fe0bd",
   "metadata": {},
   "source": [
    "from: <i><b style='color:red;'>grokking</b> <b>Deep Learning</b></i>\n",
    "<p>by Andrew W. Trask</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63007ab1-b27c-4821-a3c8-68eabfd018a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<p><b>prerequisites</b></p>\n",
    "$$f(x) = \\mathbf{w^{*}x} + b^{*},$$\n",
    "where <b>w*</b> and b* are optimal values for parameters <b>w</b> and b\n",
    "<p></p>\n",
    "<p>perceptron</p>\n",
    "<p>gradient descent</p>\n",
    "<p>backpropagation</p>\n",
    "<p><b>\"The interface for the neural network is simple: it accepts an <i>input</i> variable as information and a <i>weights</i> variable as knowledge, and it outputs a prediction.\"</b></p>\n",
    "<p><b>\"Measuring error simplifies the problem of training neural networks to make correct predictions.\"</b></p>\n",
    "<p><b>\"Different ways of measuring the error prioritize error differently.\"</b></p>\n",
    "<p>Error is calculated and applied to modify the weights during each iteration of the training.</p>\n",
    "<p><b>\"<i>alpha</i> is the simplest way to prevent overcorrecting weight updates.\"</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c002d571-a584-431a-a5e6-9615b58fac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98129caf-5db8-4877-a964-63775b48b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization, functions\n",
    "\n",
    "def gradient_descent(prediction, target):\n",
    "    ''' One method for calculating error.\n",
    "    '''\n",
    "    return (prediction - target)**2\n",
    "\n",
    "def gradient_descent_deriv(weights):\n",
    "    ''' Taking the derivative of the error\n",
    "        during training\n",
    "        yields amount and direction of the prediction\n",
    "        from the target.\n",
    "    '''\n",
    "    return (2 * weights - 1)\n",
    "    \n",
    "def relu(x):\n",
    "    ''' Returns x iff x > 0; otherwise, returns 0\n",
    "    '''\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    ''' Returns 1 for input > 0; otherwise, returns 0\n",
    "    '''\n",
    "    return output > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2c1d4fc-d285-4ec2-a68b-e23705bc8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target\n",
    "streetlights = np.array([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1]).reshape(4, 3) # layer 0 (input) & \"x\" in layer 1\n",
    "walk_v_stop = np.array([1, 1, 0, 0]).T # values to train the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "267534fd-3f53-40a9-b9be-75a174a4463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "alpha = 0.2 # scale down correction to prevent overcorrection\n",
    "hidden_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8862d4b-e9dc-47fa-8f79-422fe48def5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization, weights\n",
    "weights_0_1 = gradient_descent_deriv(np.random.random((3, hidden_size)))\n",
    "weights_1_2 = gradient_descent_deriv(np.random.random((hidden_size, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff4454ef-3de1-457e-8d1c-f6819afeb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.4594603197266258209907619\n",
      "Error: 0.0150584876951698632546739\n",
      "Error: 0.0000520447361432251450397\n",
      "Error: 0.0000001151011976940527282\n",
      "Error: 0.0000000002842043991852161\n",
      "Error: 0.0000000000009335346305984\n",
      "Error: 0.0000000000000043588528056\n",
      "Error: 0.0000000000000000257453389\n",
      "Error: 0.0000000000000000001678922\n",
      "Error: 0.0000000000000000000011316\n",
      "Error: 0.0000000000000000000000077\n",
      "Error: 0.0000000000000000000000001\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n",
      "Error: 0.0000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for iteration in range(300):\n",
    "    ''' supervised learning\n",
    "    '''\n",
    "    # reset layer_2_error to 0\n",
    "    layer_2_error = 0\n",
    "\n",
    "    for index, values in enumerate(streetlights):\n",
    "        layer_0 = streetlights[index:index+1] # rename input\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "        # difference between layer 2 output and predicted values\n",
    "        layer_2_error += np.sum(gradient_descent(layer_2, walk_v_stop[index:index+1]))\n",
    "\n",
    "        # calculate the correction\n",
    "        layer_2_delta = (layer_2 - walk_v_stop[index:index+1])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "\n",
    "        # apply the correction --- note that corrected weights are running sums\n",
    "        # alpha is a fractional value to dampen correction, preventing overcorrection\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if (iteration % 10 == 9):\n",
    "        print(f\"Error: {layer_2_error:.25f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72dc9ef3-2775-469e-b569-ac8bf7d36e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type        Data/Info\n",
      "----------------------------------------------\n",
      "alpha                    float       0.2\n",
      "gradient_descent         function    <function gradient_descent at 0x72c91998c720>\n",
      "gradient_descent_deriv   function    <function gradient_descen<...>_deriv at 0x72c8bcd47ec0>\n",
      "hidden_size              int         4\n",
      "index                    int         3\n",
      "iteration                int         149\n",
      "layer_0                  ndarray     1x3: 3 elems, type `int64`, 24 bytes\n",
      "layer_1                  ndarray     1x4: 4 elems, type `float64`, 32 bytes\n",
      "layer_1_delta            ndarray     1x4: 4 elems, type `float64`, 32 bytes\n",
      "layer_2                  ndarray     1x1: 1 elems, type `float64`, 8 bytes\n",
      "layer_2_delta            ndarray     1x1: 1 elems, type `float64`, 8 bytes\n",
      "layer_2_error            float64     4.905728754343167e-30\n",
      "np                       module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "relu                     function    <function relu at 0x72c8bcd46840>\n",
      "relu2deriv               function    <function relu2deriv at 0x72c8bcd47ce0>\n",
      "streetlights             ndarray     4x3: 12 elems, type `int64`, 96 bytes\n",
      "test_m                   ndarray     4x1: 4 elems, type `float64`, 32 bytes\n",
      "test_val                 ndarray     3x4: 12 elems, type `float64`, 96 bytes\n",
      "values                   ndarray     3: 3 elems, type `int64`, 24 bytes\n",
      "walk_v_stop              ndarray     4: 4 elems, type `int64`, 32 bytes\n",
      "weights_0_1              ndarray     3x4: 12 elems, type `float64`, 96 bytes\n",
      "weights_0_1a             ndarray     3x4: 12 elems, type `float64`, 96 bytes\n",
      "weights_0_1b             ndarray     3x4: 12 elems, type `float64`, 96 bytes\n",
      "weights_0_2a             ndarray     4x1: 4 elems, type `float64`, 32 bytes\n",
      "weights_0_2b             ndarray     4x1: 4 elems, type `float64`, 32 bytes\n",
      "weights_1_2              ndarray     4x1: 4 elems, type `float64`, 32 bytes\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be3b87fe-c511-4ae7-a55f-eeca131b76ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfix_imports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Write a pickled representation of obj to the open file object file.\n",
       "\n",
       "This is equivalent to ``Pickler(file, protocol).dump(obj)``, but may\n",
       "be more efficient.\n",
       "\n",
       "The optional *protocol* argument tells the pickler to use the given\n",
       "protocol; supported protocols are 0, 1, 2, 3, 4 and 5.  The default\n",
       "protocol is 4. It was introduced in Python 3.4, and is incompatible\n",
       "with previous versions.\n",
       "\n",
       "Specifying a negative protocol version selects the highest protocol\n",
       "version supported.  The higher the protocol used, the more recent the\n",
       "version of Python needed to read the pickle produced.\n",
       "\n",
       "The *file* argument must have a write() method that accepts a single\n",
       "bytes argument.  It can thus be a file object opened for binary\n",
       "writing, an io.BytesIO instance, or any other custom object that meets\n",
       "this interface.\n",
       "\n",
       "If *fix_imports* is True and protocol is less than 3, pickle will try\n",
       "to map the new Python 3 names to the old module names used in Python\n",
       "2, so that the pickle data stream is readable with Python 2.\n",
       "\n",
       "If *buffer_callback* is None (the default), buffer views are serialized\n",
       "into *file* as part of the pickle stream.  It is an error if\n",
       "*buffer_callback* is not None and *protocol* is None or smaller than 5.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('pickle/weights_0_1.pickle.bin', 'wb') as out_file:\n",
    "    pickle.dump(weights_0_1, out_file)\n",
    "with open('pickle/weights_1_2.pickle.bin', 'wb') as out_file:\n",
    "    pickle.dump(weights_1_2, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89e0a4ca-ae40-4cfe-a1d4-de57d73181da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "layer_0 = [1, 1, 1] # rename input\n",
    "# weights_0_1, weights_1_2\n",
    "layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "print(int(layer_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3bb401b1-6fc0-480d-8d08-5ea4a250cfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48709859e-16]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87610a6c-2e95-497b-96b5-af7f0187c2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
